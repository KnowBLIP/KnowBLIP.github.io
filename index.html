<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
        }
        .container {
            width: 80%;
            margin: 0 auto;
            padding: 20px;
        }
        h1 {
            text-align: center;
            margin-bottom: 20px;
        }
        .links {
            text-align: center;
            margin-bottom: 20px;
        }
        .links a {
            margin: 0 10px;
            text-decoration: none;
            color: #007BFF;
        }
        .section {
            margin-bottom: 40px;
        }
        .section img {
            width: 100%;
            height: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval</h1>
        <div class="links">
            <a href="#">Paper</a> | <a href="#">Code and Dataset</a>
        </div>
        <div class="section">
            <h2>Abstract</h2>
            <p>In recent years, significant developments have been made in both video retrieval and video moment retrieval tasks, which respectively retrieve complete videos or moments for a given user query. These advancements have greatly improved user satisfaction during the search process. However, previous work has failed to establish meaningful "interaction" between the retrieval system and the user, and its one-way retrieval paradigm can no longer fully meet the personalization and dynamics of user needs. In this paper, we propose a new interactive video retrieval framework: Interactive Video Corpus Retrieval (IVCR) that enables multi-turn retrieval, considering user feedback to improve the retrieval system. To facilitate research on this challenging task, we introduce IVCR-200K, a bilingual, multi-turn, conversational, abstract-to-narrative high-quality dataset that supports interactive video corpus retrieval. Furthermore, we propose a comprehensive framework based on multi-modal large language models (MLLMs) to support users' several interactions and models with more explainable solutions. Our extensive experiments demonstrate the effectiveness of our dataset and framework. The dataset and code are available as above.</p>
        </div>
        <div class="section">
            <h2>Framework</h2>
            <p>To implement an interactive video retrieval system, we constructed a multi-turn, conversational dataset comprising 193,443 interactions sourced from 5 video repositories. This dataset encompasses functionalities such as video retrieval, video moment retrieval, and natural dialogue.</p>
            <img src=./framework.png alt="Dataset images">
        </div>
    </div>
</body>
</html>
